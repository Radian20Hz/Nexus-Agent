import streamlit as st
import os
import re
import ollama
from main import NexusAgent, MODEL_NAME
from voice import text_to_speech # Importujemy gÅ‚os

# --- KONFIGURACJA STRONY ---
st.set_page_config(page_title="Nexus-Agent v3.0", page_icon="ğŸ‘ï¸", layout="wide")

# --- STYLE CSS ---
st.markdown("""
<style>
    .stTextInput > div > div > input { background-color: #000000; color: #00FF00; font-family: monospace; }
    .stMarkdown { font-family: 'Segoe UI', sans-serif; }
    div.stButton > button { background-color: #222; color: white; border: 1px solid #444; }
</style>
""", unsafe_allow_html=True)

# --- INICJALIZACJA ---
if "agent" not in st.session_state:
    st.session_state.agent = NexusAgent(MODEL_NAME)

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- SIDEBAR (PANEL STEROWANIA) ---
with st.sidebar:
    st.title("ğŸ‘ï¸ Nexus Vision")
    
    # 1. KAMERA
    st.markdown("### ğŸ“¸ Oczy Agenta")
    enable_camera = st.toggle("WÅ‚Ä…cz KamerÄ™")
    img_file_buffer = None
    
    if enable_camera:
        img_file_buffer = st.camera_input("PokaÅ¼ coÅ› Agentowi")
    
    # 2. GÅOS
    st.markdown("### ğŸ”Š ModuÅ‚ GÅ‚osu")
    enable_voice = st.toggle("MÃ³w do mnie (TTS)", value=False)
    
    # 3. RAG
    st.markdown("---")
    st.markdown("### ğŸ“š Baza Wiedzy")
    uploaded_file = st.file_uploader("Dodaj plik", type=["pdf", "txt"])
    if uploaded_file:
        save_path = os.path.join("workspace", uploaded_file.name)
        with open(save_path, "wb") as f: f.write(uploaded_file.getbuffer())
        with st.spinner("TrawiÄ™ dane..."):
            st.session_state.agent.knowledge.ingest_file(save_path)
        st.success("Wgrano!")

    # 4. RESET
    st.markdown("---")
    if st.button("ğŸ”´ RESET PAMIÄ˜CI"):
        st.session_state.messages = []
        st.session_state.agent.memory = [{"role": "system", "content": st.session_state.agent.system_prompt}]
        st.rerun()

# --- LOGIKA KAMERY (AUTO-ANALIZA) ---
if img_file_buffer is not None:
    # Zapisz zdjÄ™cie
    bytes_data = img_file_buffer.getvalue()
    img_path = os.path.join("workspace", "camera_capture.jpg")
    with open(img_path, "wb") as f:
        f.write(bytes_data)
    
    # JeÅ›li uÅ¼ytkownik zrobiÅ‚ zdjÄ™cie, automatycznie wyÅ›lij je do analizy
    # Ale tylko jeÅ›li nie zrobiliÅ›my tego w tej samej sekundzie (zapobieganie pÄ™tli)
    if "last_photo" not in st.session_state or st.session_state.last_photo != len(bytes_data):
        st.session_state.last_photo = len(bytes_data)
        prompt = "SpÃ³jrz na plik camera_capture.jpg. Opisz co widzisz i jeÅ›li to tekst lub kod - przepisz go."
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.session_state.agent.memory.append({"role": "user", "content": prompt})
        # Wymuszamy odÅ›wieÅ¼enie, Å¼eby czat "zauwaÅ¼yÅ‚" nowÄ… wiadomoÅ›Ä‡
        st.rerun()

# --- CZAT ---
st.title("ğŸ§  Nexus-Agent")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        # JeÅ›li to wiadomoÅ›Ä‡ asystenta i ma plik audio, odtwÃ³rz go
        if message["role"] == "assistant" and "audio" in message:
            st.audio(message["audio"], format="audio/mp3", start_time=0)

# --- POLE TEKSTOWE ---
if prompt := st.chat_input("Wpisz polecenie..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.agent.memory.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            with st.spinner("Przetwarzam..."):
                # GÅÃ“WNA PÄ˜TLA MYÅšLENIA
                response = ollama.chat(model=MODEL_NAME, messages=st.session_state.agent.memory)['message']['content']
                
                full_response += response
                message_placeholder.markdown(full_response)
                
                # TOOL USE
                action_match = re.search(r"Action:\s*(.*)", response)
                input_match = re.search(r"Action Input:\s*(.*)", response)
                
                if action_match:
                    action = action_match.group(1).strip()
                    act_input = input_match.group(1).strip().strip('"') if input_match else ""
                    st.toast(f"ğŸ› ï¸ {action}", icon="âš¡")
                    
                    result = st.session_state.agent.execute_tool(action, act_input, response)
                    
                    obs = f"\n\n**Observation:**\n```\n{result}\n```"
                    full_response += obs
                    message_placeholder.markdown(full_response)
                    
                    st.session_state.agent.memory.append({"role": "assistant", "content": response})
                    st.session_state.agent.memory.append({"role": "user", "content": f"Observation: {result}"})
                else:
                    st.session_state.agent.memory.append({"role": "assistant", "content": response})
                
                st.session_state.agent.save_memory()
                
                # GENEROWANIE GÅOSU (JeÅ›li wÅ‚Ä…czone)
                audio_path = None
                if enable_voice:
                    audio_path = text_to_speech(response)
                    if audio_path:
                        st.audio(audio_path, format="audio/mp3")

        except Exception as e:
            st.error(f"BÅ‚Ä…d: {e}")
        
        # Zapisz wiadomoÅ›Ä‡ (i Å›cieÅ¼kÄ™ do audio) w historii sesji
        msg_data = {"role": "assistant", "content": full_response}
        if enable_voice and audio_path:
             msg_data["audio"] = audio_path
        st.session_state.messages.append(msg_data)